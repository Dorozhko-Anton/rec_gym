{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/anton/Datasets/MovieLens/ml-100k/u.genre\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/anton/Datasets/MovieLens/ml-100k/u.genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unknown|0\r\n",
      "Action|1\r\n",
      "Adventure|2\r\n",
      "Animation|3\r\n",
      "Children's|4\r\n",
      "Comedy|5\r\n",
      "Crime|6\r\n",
      "Documentary|7\r\n",
      "Drama|8\r\n",
      "Fantasy|9\r\n",
      "Film-Noir|10\r\n",
      "Horror|11\r\n",
      "Musical|12\r\n",
      "Mystery|13\r\n",
      "Romance|14\r\n",
      "Sci-Fi|15\r\n",
      "Thriller|16\r\n",
      "War|17\r\n",
      "Western|18\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!cat /home/anton/Datasets/MovieLens/ml-100k/u.genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allbut.pl  u1.base  u2.test  u4.base  u5.test  ub.base\tu.genre  u.occupation\r\n",
      "mku.sh\t   u1.test  u3.base  u4.test  ua.base  ub.test\tu.info\t u.user\r\n",
      "README\t   u2.base  u3.test  u5.base  ua.test  u.data\tu.item\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/anton/Datasets/MovieLens/ml-100k/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_csv('/home/anton/Datasets/MovieLens/ml-100k/u.user', sep='|', names=['age', 'gender', 'occupation', 'id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rec_gym.envs import MovieLensDRR, MovieLens100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = MovieLens100(\n",
    "                 n_items_to_recommend=1,\n",
    "                 env_seed=5,\n",
    "                 normalize_reward=False,\n",
    "                 session_time=None,\n",
    "                 session_size=20,\n",
    "                 shuffle_sessions=True,\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rec_gym.wrappers import BaselinesWrapper, DRR_BaselinesWrapper, StatsWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = MovieLens100(\n",
    "                 n_items_to_recommend=1,\n",
    "                 env_seed=5,\n",
    "                 normalize_reward=False,\n",
    "                 session_time=None,\n",
    "                 session_size=20,\n",
    "                 shuffle_sessions=True,\n",
    "                 )\n",
    "\n",
    "e = StatsWrapper(e)\n",
    "e = DRR_BaselinesWrapper(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/anton/anaconda3/envs/datascience/lib/python3.7/site-packages/stable_baselines/ddpg/policies.py:136: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /home/anton/anaconda3/envs/datascience/lib/python3.7/site-packages/stable_baselines/ddpg/policies.py:138: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /home/anton/anaconda3/envs/datascience/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "from stable_baselines.ddpg.policies import MlpPolicy\n",
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "from stable_baselines.ddpg.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise, AdaptiveParamNoiseSpec\n",
    "from stable_baselines import DDPG\n",
    "\n",
    "env = e\n",
    "\n",
    "# the noise objects for DDPG\n",
    "n_actions = env.action_space.shape[-1]\n",
    "param_noise = None\n",
    "action_noise = OrnsteinUhlenbeckActionNoise(mean=np.zeros(n_actions), sigma=float(0.5) * np.ones(n_actions))\n",
    "\n",
    "model = DDPG(MlpPolicy, env, verbose=1, param_noise=param_noise, action_noise=action_noise, _init_setup_model=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anton/anaconda3/envs/datascience/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: <class 'rec_gym.wrappers.baselines_wrapper.DRR_BaselinesWrapper'> doesn't implement 'reset' method, which is required for wrappers derived directly from Wrapper. Deprecated default implementation is used.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device   = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.buffer = []\n",
    "        self.position = 0\n",
    "    \n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        if len(self.buffer) < self.capacity:\n",
    "            self.buffer.append(None)\n",
    "        self.buffer[self.position] = (state, action, reward, next_state, done)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        batch = random.sample(self.buffer, batch_size)\n",
    "        state, action, reward, next_state, done = map(np.stack, zip(*batch))\n",
    "        return state, action, reward, next_state, done\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalizedActions(gym.ActionWrapper):\n",
    "\n",
    "    def _action(self, action):\n",
    "        low_bound   = self.action_space.low\n",
    "        upper_bound = self.action_space.high\n",
    "        \n",
    "        action = low_bound + (action + 1.0) * 0.5 * (upper_bound - low_bound)\n",
    "        action = np.clip(action, low_bound, upper_bound)\n",
    "        \n",
    "        return action\n",
    "\n",
    "    def _reverse_action(self, action):\n",
    "        low_bound   = self.action_space.low\n",
    "        upper_bound = self.action_space.high\n",
    "        \n",
    "        action = 2 * (action - low_bound) / (upper_bound - low_bound) - 1\n",
    "        action = np.clip(action, low_bound, upper_bound)\n",
    "        \n",
    "        return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OUNoise(object):\n",
    "    def __init__(self, action_space, mu=0.0, theta=0.15, max_sigma=0.3, min_sigma=0.3, decay_period=100000):\n",
    "        self.mu           = mu\n",
    "        self.theta        = theta\n",
    "        self.sigma        = max_sigma\n",
    "        self.max_sigma    = max_sigma\n",
    "        self.min_sigma    = min_sigma\n",
    "        self.decay_period = decay_period\n",
    "        self.action_dim   = action_space.shape[0]\n",
    "        self.low          = action_space.low\n",
    "        self.high         = action_space.high\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.state = np.ones(self.action_dim) * self.mu\n",
    "        \n",
    "    def evolve_state(self):\n",
    "        x  = self.state\n",
    "        dx = self.theta * (self.mu - x) + self.sigma * np.random.randn(self.action_dim)\n",
    "        self.state = x + dx\n",
    "        return self.state\n",
    "    \n",
    "    def get_action(self, action, t=0):\n",
    "        ou_state = self.evolve_state()\n",
    "        self.sigma = self.max_sigma - (self.max_sigma - self.min_sigma) * min(1.0, t / self.decay_period)\n",
    "        return np.clip(action + ou_state, self.low, self.high)\n",
    "    \n",
    "#https://github.com/vitchyr/rlkit/blob/master/rlkit/exploration_strategies/ou_strategy.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(frame_idx, rewards):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(131)\n",
    "    plt.title('frame %s. reward: %s' % (frame_idx, rewards[-1]))\n",
    "    plt.plot(rewards)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValueNetwork(nn.Module):\n",
    "    def __init__(self, num_inputs, num_actions, hidden_size, init_w=3e-3):\n",
    "        super(ValueNetwork, self).__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear(num_inputs + num_actions, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.linear3 = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "        self.linear3.weight.data.uniform_(-init_w, init_w)\n",
    "        self.linear3.bias.data.uniform_(-init_w, init_w)\n",
    "        \n",
    "    def forward(self, state, action):\n",
    "        x = torch.cat([state, action], 1)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class PolicyNetwork(nn.Module):\n",
    "    def __init__(self, num_inputs, num_actions, hidden_size, init_w=3e-3):\n",
    "        super(PolicyNetwork, self).__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear(num_inputs, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.linear3 = nn.Linear(hidden_size, num_actions)\n",
    "        \n",
    "        self.linear3.weight.data.uniform_(-init_w, init_w)\n",
    "        self.linear3.bias.data.uniform_(-init_w, init_w)\n",
    "        \n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.linear1(state))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = torch.tanh(self.linear3(x))\n",
    "        return x\n",
    "    \n",
    "    def get_action(self, state):\n",
    "        state  = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
    "        action = self.forward(state)\n",
    "        return action.detach().cpu().numpy()[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ddpg_update(batch_size, \n",
    "           gamma = 0.99,\n",
    "           min_value=-np.inf,\n",
    "           max_value=np.inf,\n",
    "           soft_tau=1e-2):\n",
    "    \n",
    "    state, action, reward, next_state, done = replay_buffer.sample(batch_size)\n",
    "    \n",
    "    state      = torch.FloatTensor(state).to(device)\n",
    "    next_state = torch.FloatTensor(next_state).to(device)\n",
    "    action     = torch.FloatTensor(action).to(device)\n",
    "    reward     = torch.FloatTensor(reward).unsqueeze(1).to(device)\n",
    "    done       = torch.FloatTensor(np.float32(done)).unsqueeze(1).to(device)\n",
    "\n",
    "    policy_loss = value_net(state, policy_net(state))\n",
    "    policy_loss = -policy_loss.mean()\n",
    "\n",
    "    next_action    = target_policy_net(next_state)\n",
    "    target_value   = target_value_net(next_state, next_action.detach())\n",
    "    expected_value = reward + (1.0 - done) * gamma * target_value\n",
    "    expected_value = torch.clamp(expected_value, min_value, max_value)\n",
    "\n",
    "    value = value_net(state, action)\n",
    "    value_loss = value_criterion(value, expected_value.detach())\n",
    "    \n",
    "#     print(value_loss, policy_loss)\n",
    "        \n",
    "    policy_optimizer.zero_grad()\n",
    "    policy_loss.backward()\n",
    "    policy_optimizer.step()\n",
    "\n",
    "    value_optimizer.zero_grad()\n",
    "    value_loss.backward()\n",
    "    value_optimizer.step()\n",
    "\n",
    "    for target_param, param in zip(target_value_net.parameters(), value_net.parameters()):\n",
    "            target_param.data.copy_(\n",
    "                target_param.data * (1.0 - soft_tau) + param.data * soft_tau\n",
    "            )\n",
    "\n",
    "    for target_param, param in zip(target_policy_net.parameters(), policy_net.parameters()):\n",
    "            target_param.data.copy_(\n",
    "                target_param.data * (1.0 - soft_tau) + param.data * soft_tau\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e = MovieLens100(\n",
    "#                  n_items_to_recommend=1,\n",
    "#                  env_seed=5,\n",
    "#                  normalize_reward=False,\n",
    "#                  session_time=None,\n",
    "#                  session_size=20,\n",
    "#                  shuffle_sessions=True,\n",
    "#                  )\n",
    "\n",
    "# e = StatsWrapper(e)\n",
    "# e = DRR_BaselinesWrapper(e)\n",
    "\n",
    "def make_env(session_size=10, seed=123):\n",
    "#     env = MovieLens100(\n",
    "#                  n_items_to_recommend=1,\n",
    "#                  env_seed=seed,\n",
    "#                  normalize_reward=False,\n",
    "#                  session_time=None,\n",
    "#                  session_size=session_size,\n",
    "#                  shuffle_sessions=True,\n",
    "#                  )  \n",
    "    CACHE_DIR = \"/home/anton/cache\"\n",
    "    \n",
    "    \n",
    "    env = MovieLensDRR(embedding_dimension=20, \n",
    "             n_items_to_recommend=1, \n",
    "             env_seed=seed,\n",
    "             normalize_reward=True,\n",
    "#              filename=\"/home/anton/Datasets/MovieLens/ml-100k/u.data\",\n",
    "#              sep='\\t',\n",
    "             filename=\"/home/anton/Datasets/MovieLens/ml-1m/ratings.dat\",\\\n",
    "             sep='::',\\\n",
    "#              session_time = 20 * 60,\n",
    "             session_size = session_size,\n",
    "             cache_dir=CACHE_DIR,\n",
    "             shuffle_sessions=False)\n",
    "    \n",
    "#     env = MovieLensDRR(embedding_dimension=40, \n",
    "#              n_items_to_recommend=1, \n",
    "#              env_seed=seed,\n",
    "#              normalize_reward=True,\n",
    "#              filename=\"/home/anton/Datasets/MovieLens/ml-100k/u.data\",\n",
    "#              sep='\\t',\n",
    "#     #              session_time = 20 * 60,\n",
    "#              session_size = session_size,\n",
    "#              cache_dir=CACHE_DIR,\n",
    "#              shuffle_sessions=True\n",
    "#                       )\n",
    "    \n",
    "    env = StatsWrapper(env)\n",
    "    env = DRR_BaselinesWrapper(env)\n",
    "    return env\n",
    "\n",
    "envs_kv = { 'ml_100k_s20_seed{}'.format(x) : lambda: make_env(20, x) \n",
    "             for x in [100] }\n",
    "\n",
    "import tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8ab6833286740958935326a9821e6a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/0b9d5a44-bb63-4de1-9cfe-0da47b81e88a/TPT/3A/PRIM Vente Privee/WORK_DIR/rec_gym/rec_gym/envs/MovieLensDRR.py:61: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  data = pd.read_csv(self.filename, sep=sep, names=data_columns)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "add83cb3709b40d0a0fdc52a4fdfc618",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=800000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "165fe18755e34d7fb4057812bc4d1b62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=190000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = defaultdict(defaultdict)\n",
    "\n",
    "for name, env_fn in tqdm.tqdm_notebook(envs_kv.items()):\n",
    "    \n",
    "    env = env_fn()\n",
    "    \n",
    "    ou_noise = OUNoise(env.action_space)\n",
    "\n",
    "    state_dim  = env.observation_space.shape[0]\n",
    "    action_dim = env.action_space.shape[0]\n",
    "    hidden_dim = 32\n",
    "\n",
    "    value_net  = ValueNetwork(state_dim, action_dim, hidden_dim).to(device)\n",
    "    policy_net = PolicyNetwork(state_dim, action_dim, hidden_dim).to(device)\n",
    "\n",
    "    target_value_net  = ValueNetwork(state_dim, action_dim, hidden_dim).to(device)\n",
    "    target_policy_net = PolicyNetwork(state_dim, action_dim, hidden_dim).to(device)\n",
    "\n",
    "    for target_param, param in zip(target_value_net.parameters(), value_net.parameters()):\n",
    "        target_param.data.copy_(param.data)\n",
    "\n",
    "    for target_param, param in zip(target_policy_net.parameters(), policy_net.parameters()):\n",
    "        target_param.data.copy_(param.data)\n",
    "\n",
    "\n",
    "    value_lr  = 1e-3\n",
    "    policy_lr = 1e-4\n",
    "\n",
    "    value_optimizer  = optim.Adam(value_net.parameters(),  lr=value_lr)\n",
    "    policy_optimizer = optim.Adam(policy_net.parameters(), lr=policy_lr)\n",
    "\n",
    "    value_criterion = nn.MSELoss()\n",
    "\n",
    "    replay_buffer_size = 1000\n",
    "    replay_buffer = ReplayBuffer(replay_buffer_size)\n",
    "\n",
    "\n",
    "    obs0 = env.reset()\n",
    "\n",
    "    for i in tqdm.tqdm_notebook(range(800000)):\n",
    "\n",
    "        action = env.unwrapped.get_ground_truth_action(emb=True).embedding\n",
    "        obs1, reward, terminal1, info = env.step(action)\n",
    "\n",
    "    #     model._store_transition(obs0, action, reward, obs1, terminal1)\n",
    "\n",
    "        replay_buffer.push(state=obs0[0], action=action, \n",
    "                           reward=reward, next_state=obs1[0], done=terminal1)\n",
    "        \n",
    "        batch_size = 64\n",
    "        if i % 50 == 0:\n",
    "            if len(replay_buffer) > batch_size:\n",
    "                ddpg_update(batch_size)\n",
    "        \n",
    "        if terminal1:\n",
    "            obs0 = env.reset()\n",
    "        else:\n",
    "            obs0 = obs1\n",
    "\n",
    "\n",
    "#     for i in tqdm.tqdm_notebook(range(100)):\n",
    "#         ddpg_update(batch_size=64)\n",
    "\n",
    "    for i in tqdm.tqdm_notebook(range(190000)):\n",
    "        a = policy_net.get_action(obs0)\n",
    "        obs1, reward, terminal1, info = env.step(action)\n",
    "\n",
    "        if terminal1:\n",
    "            obs0 = env.reset()\n",
    "        else:\n",
    "            obs0 = obs1\n",
    "            \n",
    "    results[name]['ddpg'] = env.env.interactions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(recs, gt, k):\n",
    "    relevant_items = set(gt[:k])\n",
    "    \n",
    "    rec_rel = [item in relevant_items for item in recs[:k]]\n",
    "    return np.mean(rec_rel)\n",
    "    \n",
    "    \n",
    "def precision_at_k_thresh(rewards, k, threshold=0.):\n",
    "    rec_rel = [r >= threshold for r in rewards[:k]]\n",
    "    return np.mean(rec_rel)\n",
    "\n",
    "def dcg_at_k(rewards, k):\n",
    "    dcg = 0\n",
    "    for i, r in enumerate(rewards[:k]):\n",
    "        if i == 0:\n",
    "            dcg += r\n",
    "        else:\n",
    "            dcg += 2**r - 1 / np.log2(i+1)\n",
    "    return dcg\n",
    "\n",
    "def ndcg_at_k(rewards, k):\n",
    "    maxdcg = dcg_at_k(np.sort(rewards)[::-1], k)\n",
    "    if maxdcg == 0: return 0\n",
    "    return dcg_at_k(rewards, k) / maxdcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "TRAIN_STEPS = 800000\n",
    "EVAL_STEPS = 190000\n",
    "THRESH = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            |Precision@5 |Precision@10|Precision@15|Precision@20|NDCG@5      |NDCG@10     |NDCG@15     |NDCG@20     \n",
      "ddpg        |0.75 +-0.000|0.73 +-0.000|0.70 +-0.000|0.65 +-0.000|0.80 +-0.000|0.82 +-0.000|0.82 +-0.000|0.80 +-0.000\n",
      "            |Precision@5 |Precision@10|Precision@15|Precision@20|NDCG@5      |NDCG@10     |NDCG@15     |NDCG@20     \n",
      "ddpg        |0.41 +-0.000|0.39 +-0.000|0.36 +-0.000|0.31 +-0.000|0.55 +-0.000|0.62 +-0.000|0.66 +-0.000|0.67 +-0.000\n"
     ]
    }
   ],
   "source": [
    "all_metrics = defaultdict(lambda: defaultdict(dict))\n",
    "\n",
    "for THRESH in [0.5, 0.6]:\n",
    "\n",
    "    for dataset_name in results:\n",
    "        for algorithm in results[dataset_name]:\n",
    "            metrics = {}\n",
    "\n",
    "            interactions = results[dataset_name][algorithm]\n",
    "            session_recs_by_user = defaultdict(lambda : defaultdict(list))\n",
    "            session_gt_by_user = defaultdict(lambda : defaultdict(list))\n",
    "            session_rewards_by_user = defaultdict(lambda : defaultdict(list))\n",
    "\n",
    "            prev_user = None\n",
    "\n",
    "            for i in interactions[TRAIN_STEPS:]:\n",
    "                u = i.uid \n",
    "                recs = i.recs\n",
    "                gt = i.raw_info['ground_truth_items']\n",
    "                rewards = i.rewards\n",
    "\n",
    "                if prev_user is None or u != prev_user:\n",
    "                    prev_user = u\n",
    "                    user_session = len(session_recs_by_user[prev_user])\n",
    "\n",
    "                session_recs_by_user[prev_user][user_session].extend(recs)\n",
    "                session_gt_by_user[prev_user][user_session].extend(gt)\n",
    "                session_rewards_by_user[prev_user][user_session].extend(rewards)\n",
    "\n",
    "\n",
    "            for K in [5, 10, 15, 20]:\n",
    "\n",
    "                precisions = []\n",
    "                precisions_thresh = []\n",
    "                ndcgs = []\n",
    "\n",
    "                for k, v in session_recs_by_user.items():\n",
    "                    for session_number in v:\n",
    "\n",
    "                        recs = session_recs_by_user[k][session_number]\n",
    "                        gt = session_gt_by_user[k][session_number]\n",
    "                        rew = session_rewards_by_user[k][session_number]\n",
    "\n",
    "                        p_at_k = precision_at_k(recs, gt, K)\n",
    "                        precisions.append(p_at_k)\n",
    "\n",
    "                        precisions_thresh.append(precision_at_k_thresh(rew, K, THRESH))\n",
    "\n",
    "                        ndcgs.append(ndcg_at_k(np.array(rew)>=THRESH, K))\n",
    "\n",
    "\n",
    "                metrics['NDCG@{}'.format(K)] = np.mean(ndcgs)\n",
    "                metrics['Precision@{}'.format(K)] = np.mean(precisions_thresh)\n",
    "\n",
    "\n",
    "            all_metrics[dataset_name][algorithm] = metrics\n",
    "\n",
    "    metrics_by_algorithm = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "    for dataset in all_metrics:\n",
    "        for algorithm in all_metrics[dataset]:\n",
    "\n",
    "            for k, v in all_metrics[dataset][algorithm].items():\n",
    "\n",
    "                metrics_by_algorithm[algorithm][k].append(v)\n",
    "\n",
    "    metrics_names = []\n",
    "    for n in [5, 10, 15, 20]:\n",
    "        metrics_names.append('Precision@{}'.format(n))\n",
    "    for n in [5, 10, 15, 20]:\n",
    "        metrics_names.append('NDCG@{}'.format(n))\n",
    "\n",
    "\n",
    "    s = ['{:12s}'.format('')] + [ \"{:12s}\".format(m) for m in metrics_names]\n",
    "    print('|'.join(s))\n",
    "\n",
    "    for k in metrics_by_algorithm:\n",
    "        s = ['{:12s}'.format(k)]\n",
    "        for m in metrics_names:\n",
    "            s.append(\"{:1.2f} +-{:1.3f}\".format(np.mean(metrics_by_algorithm[k][m]), \n",
    "                                                 np.std(metrics_by_algorithm[k][m])))\n",
    "\n",
    "        print('|'.join(s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ddpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-95e4f51e452f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ml_100k_s30_seed100'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ddpg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'ddpg'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "results['ml_100k_s30_seed100']['ddpg'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "sns.set(font_scale=1.5) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ml_100k_s20_seed100', 'ml_100k_s30_seed100'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for name, interactions in results['ml_100k_s20_seed100'].items():\n",
    "    session_recs_by_user = defaultdict(lambda : defaultdict(list))\n",
    "    session_gt_by_user = defaultdict(lambda : defaultdict(list))\n",
    "    session_rewards_by_user = defaultdict(lambda : defaultdict(list))\n",
    "\n",
    "    prev_user = None\n",
    "\n",
    "    for i in interactions[TRAIN_STEPS:]:\n",
    "        u = i.uid \n",
    "        recs = i.recs\n",
    "        gt = i.raw_info['ground_truth_items']\n",
    "        rewards = i.rewards\n",
    "\n",
    "        if prev_user is None or u != prev_user:\n",
    "            prev_user = u\n",
    "            user_session = len(session_recs_by_user[prev_user])\n",
    "\n",
    "        session_recs_by_user[prev_user][user_session].extend(recs)\n",
    "        session_gt_by_user[prev_user][user_session].extend(gt)\n",
    "        session_rewards_by_user[prev_user][user_session].extend(rewards)\n",
    "\n",
    "    precisions = []\n",
    "    precisions_thresh = []\n",
    "    ndcgs = []\n",
    "\n",
    "    for k, v in session_recs_by_user.items():\n",
    "        for session_number in v:\n",
    "\n",
    "            recs = session_recs_by_user[k][session_number][:20]\n",
    "\n",
    "            for item in recs:\n",
    "                counts[name][item] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudpickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ddpg_1m_counts_s20', 'wb') as f:\n",
    "    cloudpickle.dump(counts, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "for name, c in counts.items():\n",
    "    plt.plot(np.cumsum(np.sort(list(c.values()))[::-1])/np.sum(list(c.values())), label=name)\n",
    "plt.legend()\n",
    "plt.show();\n",
    "\n",
    "fig.savefig('ddpg_impressions_s20.eps', format='eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state      = torch.FloatTensor(obs0).to(device)\n",
    "action =     torch.FloatTensor(policy_net.get_action(state)).unsqueeze(dim=0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_net(state, action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "datascience"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
